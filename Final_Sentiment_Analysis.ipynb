{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final-Sentiment-Analysis",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharvajpatel/AI-Hackathon-Ignition/blob/master/Final_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irxjcVFUs0PP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d4ee0985-d545-4fde-f9ca-10c291477fe6"
      },
      "source": [
        "#Importing NumPy library.\n",
        "import numpy as np\n",
        "\n",
        "#Importing Pandas library to manage data frames.\n",
        "import pandas as pd\n",
        "\n",
        "#Importing TfidfVectorizer from Sci-Kit Learn to vectorize our data set.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Importing Logistic Regression from Sci-Kit Learn as our sentiment analysis classifier/regressor.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Importing f1_score from Sci-Kit Learn to find false negatives and false positives, which .score does not provide.\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#Importing train_test_split from Sci-Kit Learn to split our data set into training data and testing data.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Importing GridSearch CV from Sci-Kit Learn to loop through predefined hyperparameters.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Importing files from google.colab to be able to import csv files.\n",
        "from google.colab import files\n",
        "\n",
        "#Importing io to help with uploading files.\n",
        "import io\n",
        "\n",
        "#importing nltk and then downloading stopwords.\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#Making a list of stop words using the stop words listed in nltk\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYaU7HvXLROW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating review class to get the sentiment\n",
        "class Review:\n",
        "\n",
        "  #Constructor of review class to set score and text.\n",
        "  def __init__(self, text, score):\n",
        "    self.text = text\n",
        "    self.score = score\n",
        "\n",
        "  #Method getSentiment is to get the sentiment based on whether it is a 1 or a 0.\n",
        "  def getSentiment(self):\n",
        "    if self.score == 1:\n",
        "      return \"Positive\"\n",
        "    else:\n",
        "      return \"Negative\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye2sYbbAtDY0",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6457bba4-b389-4879-a1d5-f8c54b53de74"
      },
      "source": [
        "#Uploading csv file to data frame.\n",
        "data = files.upload()\n",
        "df = pd.read_csv(io.BytesIO(data['training_data.csv']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6a7e978b-4380-4f5c-8c94-0e8da8a13b48\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6a7e978b-4380-4f5c-8c94-0e8da8a13b48\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving training_data.csv to training_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5vZVbhy9MTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "4396e16d-db42-43c9-9cb1-07d18e7a58ad"
      },
      "source": [
        "#Data Cleaning\n",
        "\n",
        "#Changing all letters to lowercase so that we can remove the stopwords.\n",
        "df['Clean Data'] = df['Text'].apply(lambda x: \" \".join(y.lower() for y in x.split()))\n",
        "\n",
        "#Removing the @mentions because they are unnecessary for sentiment analysis.\n",
        "df['Clean Data'] = df['Clean Data'].str.replace('([@])\\w+', '')\n",
        "\n",
        "#Removing punctuation because they do not affect sentiment analysis\n",
        "df['Clean Data'] = df['Clean Data'].str.replace('[^\\w\\s]', '')\n",
        "\n",
        "#Removing stopwords from data set.\n",
        "df['Clean Data'] = df['Clean Data'].apply(lambda x: ' '.join(y for y in x.split() if y not in stop_words))\n",
        "\n",
        "#Looking at the top 30 most common words.\n",
        "pd.Series(' '.join(df['Clean Data']).split()).value_counts()[:30]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "im        111484\n",
              "good       55981\n",
              "day        51443\n",
              "get        51097\n",
              "like       48574\n",
              "go         45500\n",
              "dont       42064\n",
              "today      40277\n",
              "going      40100\n",
              "love       39369\n",
              "cant       39353\n",
              "work       39282\n",
              "got        37948\n",
              "back       35082\n",
              "time       35003\n",
              "lol        34429\n",
              "one        32897\n",
              "u          32839\n",
              "know       31801\n",
              "really     30999\n",
              "see        28795\n",
              "well       27743\n",
              "still      26724\n",
              "want       26319\n",
              "new        26312\n",
              "think      25667\n",
              "night      25543\n",
              "amp        25289\n",
              "thanks     24522\n",
              "home       24506\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGWNm3flAoev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating list of new stopwords from the list of common words from the previous cell.\n",
        "\n",
        "#This words in the list are then removed from the data set.\n",
        "new_stopwords = ['im', 'got', 'get', 'dont', 'going', 'cant', 'got', 'today']\n",
        "df['Clean Data'] = df['Clean Data'].apply(lambda x: \" \".join(y for y in x.split() if y not in new_stopwords))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZchSl7Rt87qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parsing the data for all the important stuff. 1D list with the review objects for each row\n",
        "review = []\n",
        "#The for loop syntax that goes through the entire data set, index being each row number, and rows being all the data in each row\n",
        "for index, rows in df.iterrows():\n",
        "  #Rather than creating 2D list, have a list of objects where we can access their properties polymorphically\n",
        "  review.append(Review(df.iloc[index, 4], df.iloc[index,3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyCUBVLHwaAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use train_test_split method to seperate and filter the data into training and testing. \n",
        "train, test = train_test_split(review, test_size=0.25,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TedDn6uIxbc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a vectorizer to utilize bag of words model and then to convert the text to numbers \n",
        "\n",
        "tfv=TfidfVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc9ETlS1xTOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split the train values into trainX and trainY so that we can vectorize then fit\n",
        "\n",
        "#As review and train contain objects (polymorphic array), call their \"text\" field and getSentiment() method to get those niche values into each individual variable \n",
        "trainX = [x.text for x in train]\n",
        "trainY = [x.getSentiment() for x in train]\n",
        "\n",
        "#Same thing here\n",
        "testX = [x.text for x in test]\n",
        "testY = [x.getSentiment() for x in test]\n",
        "\n",
        "#Create sparse trainX_vector array to get vectorized values using fit_transform to use in the fit method \n",
        "trainX_vector = tfv.fit_transform(trainX)\n",
        "\n",
        "#Create sparse testX_vector array to get vectorized values. As we don't need to fit this data (we use it in the .score) we use just .transform()\n",
        "testX_vector = tfv.transform(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23tNOvjpyVFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d8d0e1d-4dce-441b-f236-189d237b1dbd"
      },
      "source": [
        "#A dictionary to store all the values that the grid search will be using to hyper tune\n",
        "\n",
        "'''\n",
        "param_grid explanation of each value = {\n",
        "\n",
        "  'PENALTY':\n",
        "  Penalty is a logistic regression parameter that allows us to prevent overfitting and allowing the model to better predict unseen \n",
        "  data. The key difference between these parameters is that L1 shrinks the less important feature’s coefficient to zero thus, removing some \n",
        "  feature altogether. So, this works well for feature selection in case we have a huge number of features.  ,\n",
        "  \n",
        "  'C': \n",
        "  The C value is the inverse regularization strength. Basically the lower the C value, the higher strength of regularization, which mentioned as \n",
        "  above prevents overfitting. Since we have such a large dataset, we use really low C values because we want the regularization to be stronger. \n",
        "  However when working with smaller data sets, it should be noted that it is important to not overcompensate for overfitting so you should use a\n",
        "  larger C value in that case\n",
        "\n",
        "  'SOLVER':\n",
        "  A solver is basically a graphical parameter that we use in our logistic regression model. We use the solvers 'newton-cg', 'liblinear', and 'lbfgs'.\n",
        "  Each of these uses different methods to find the global optima, which is the minimum value of the cost or loss function. A graph of the \n",
        "  cost or loss function would show us a line that runs through all the parameters in a hypothesis (can be anything from a simple one variable \n",
        "  equation to a lengthy multivariate equation) that are used to minimize the error in predicting the output. The cost or loss function can be \n",
        "  represented by either a smooth line and distinguishable shape, or a bumpy line and a non-distinguishable shape. The global optima is sometimes hard\n",
        "  to predict using a function because of the shape and size of the cost or loss function. That is where the solvers come in. The default solver, \n",
        "  'sag' is optimized for smaller data sets, but the other three that we used are more suitable for our specific data set.\n",
        "\n",
        "}\n",
        "'''\n",
        "\n",
        "param_grid =  {\n",
        "    'penalty' : ['l1', 'l2'],\n",
        "    'C': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1, 2],\n",
        "    'solver' : ['lbfgs','newton-cg','liblinear'],\n",
        "}\n",
        "\n",
        "'''\n",
        "Using the GridSearchCV method to hyper tune. Use the logistic regression classifier and try all combinations and permutations of dictionary param\n",
        "to find the best variable values to use for each data point. Pass cv as 4 (cross validation fold) to make sure all the data is accurately used. Pass\n",
        "in verbose to display all the runtime data.\n",
        "'''\n",
        "grid = GridSearchCV(LogisticRegression(max_iter= len(trainX)+1), param_grid, cv=4, verbose = 5)\n",
        "\n",
        "#The fit method which actually trains the model to recognize sentiments\n",
        "grid.fit(trainX_vector, trainY)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 54 candidates, totalling 216 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] C=1e-06, penalty=l1, solver=lbfgs ...............................\n",
            "[CV] ..... C=1e-06, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1e-06, penalty=l1, solver=lbfgs ...............................\n",
            "[CV] ..... C=1e-06, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1e-06, penalty=l1, solver=lbfgs ...............................\n",
            "[CV] ..... C=1e-06, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1e-06, penalty=l1, solver=lbfgs ...............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ..... C=1e-06, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1e-06, penalty=l1, solver=newton-cg ...........................\n",
            "[CV] . C=1e-06, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1e-06, penalty=l1, solver=newton-cg ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . C=1e-06, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1e-06, penalty=l1, solver=newton-cg ...........................\n",
            "[CV] . C=1e-06, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1e-06, penalty=l1, solver=newton-cg ...........................\n",
            "[CV] . C=1e-06, penalty=l1, solver=newton-cg, score=nan, total=   0.2s\n",
            "[CV] C=1e-06, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=1e-06, penalty=l1, solver=liblinear, score=0.500, total=   1.2s\n",
            "[CV] C=1e-06, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=1e-06, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=1e-06, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=1e-06, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=1e-06, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=1e-06, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=1e-06, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=1e-06, penalty=l2, solver=lbfgs, score=0.523, total=   1.8s\n",
            "[CV] C=1e-06, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=1e-06, penalty=l2, solver=lbfgs, score=0.523, total=   1.8s\n",
            "[CV] C=1e-06, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=1e-06, penalty=l2, solver=lbfgs, score=0.523, total=   1.8s\n",
            "[CV] C=1e-06, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=1e-06, penalty=l2, solver=lbfgs, score=0.524, total=   1.8s\n",
            "[CV] C=1e-06, penalty=l2, solver=newton-cg ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1e-06, penalty=l2, solver=newton-cg, score=0.525, total=  16.5s\n",
            "[CV] C=1e-06, penalty=l2, solver=newton-cg ...........................\n",
            "[CV]  C=1e-06, penalty=l2, solver=newton-cg, score=0.525, total=   2.4s\n",
            "[CV] C=1e-06, penalty=l2, solver=newton-cg ...........................\n",
            "[CV]  C=1e-06, penalty=l2, solver=newton-cg, score=0.526, total=   2.4s\n",
            "[CV] C=1e-06, penalty=l2, solver=newton-cg ...........................\n",
            "[CV]  C=1e-06, penalty=l2, solver=newton-cg, score=0.526, total=   2.5s\n",
            "[CV] C=1e-06, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=1e-06, penalty=l2, solver=liblinear, score=0.701, total=   1.4s\n",
            "[CV] C=1e-06, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=1e-06, penalty=l2, solver=liblinear, score=0.701, total=   1.4s\n",
            "[CV] C=1e-06, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=1e-06, penalty=l2, solver=liblinear, score=0.700, total=   1.4s\n",
            "[CV] C=1e-06, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=1e-06, penalty=l2, solver=liblinear, score=0.701, total=   1.4s\n",
            "[CV] C=1e-05, penalty=l1, solver=lbfgs ...............................\n",
            "[CV] ..... C=1e-05, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=lbfgs ...............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ..... C=1e-05, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=lbfgs ...............................\n",
            "[CV] ..... C=1e-05, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=lbfgs ...............................\n",
            "[CV] ..... C=1e-05, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=newton-cg ...........................\n",
            "[CV] . C=1e-05, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=newton-cg ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . C=1e-05, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=newton-cg ...........................\n",
            "[CV] . C=1e-05, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=newton-cg ...........................\n",
            "[CV] . C=1e-05, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=1e-05, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=1e-05, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=1e-05, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=1e-05, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=1e-05, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=1e-05, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=1e-05, penalty=l2, solver=lbfgs, score=0.703, total=   1.5s\n",
            "[CV] C=1e-05, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=1e-05, penalty=l2, solver=lbfgs, score=0.703, total=   1.5s\n",
            "[CV] C=1e-05, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=1e-05, penalty=l2, solver=lbfgs, score=0.702, total=   1.5s\n",
            "[CV] C=1e-05, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=1e-05, penalty=l2, solver=lbfgs, score=0.703, total=   1.5s\n",
            "[CV] C=1e-05, penalty=l2, solver=newton-cg ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1e-05, penalty=l2, solver=newton-cg, score=0.703, total=  13.0s\n",
            "[CV] C=1e-05, penalty=l2, solver=newton-cg ...........................\n",
            "[CV]  C=1e-05, penalty=l2, solver=newton-cg, score=0.703, total=   4.9s\n",
            "[CV] C=1e-05, penalty=l2, solver=newton-cg ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1e-05, penalty=l2, solver=newton-cg, score=0.702, total=   5.2s\n",
            "[CV] C=1e-05, penalty=l2, solver=newton-cg ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1e-05, penalty=l2, solver=newton-cg, score=0.703, total=  14.8s\n",
            "[CV] C=1e-05, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=1e-05, penalty=l2, solver=liblinear, score=0.717, total=   1.7s\n",
            "[CV] C=1e-05, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=1e-05, penalty=l2, solver=liblinear, score=0.718, total=   1.7s\n",
            "[CV] C=1e-05, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=1e-05, penalty=l2, solver=liblinear, score=0.716, total=   1.7s\n",
            "[CV] C=1e-05, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=1e-05, penalty=l2, solver=liblinear, score=0.717, total=   1.7s\n",
            "[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n",
            "[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n",
            "[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n",
            "[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=newton-cg ..........................\n",
            "[CV]  C=0.0001, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=newton-cg ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=newton-cg ..........................\n",
            "[CV]  C=0.0001, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=newton-cg ..........................\n",
            "[CV]  C=0.0001, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n",
            "[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n",
            "[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n",
            "[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n",
            "[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.500, total=   1.1s\n",
            "[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n",
            "[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.726, total=   1.9s\n",
            "[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n",
            "[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.727, total=   2.0s\n",
            "[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n",
            "[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.726, total=   2.0s\n",
            "[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n",
            "[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.727, total=   2.0s\n",
            "[CV] C=0.0001, penalty=l2, solver=newton-cg ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, penalty=l2, solver=newton-cg, score=0.726, total=   3.8s\n",
            "[CV] C=0.0001, penalty=l2, solver=newton-cg ..........................\n",
            "[CV]  C=0.0001, penalty=l2, solver=newton-cg, score=0.727, total=   3.5s\n",
            "[CV] C=0.0001, penalty=l2, solver=newton-cg ..........................\n",
            "[CV]  C=0.0001, penalty=l2, solver=newton-cg, score=0.726, total=   3.4s\n",
            "[CV] C=0.0001, penalty=l2, solver=newton-cg ..........................\n",
            "[CV]  C=0.0001, penalty=l2, solver=newton-cg, score=0.727, total=   3.4s\n",
            "[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n",
            "[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.726, total=   1.9s\n",
            "[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n",
            "[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.728, total=   1.9s\n",
            "[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n",
            "[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.726, total=   1.9s\n",
            "[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n",
            "[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.727, total=   1.8s\n",
            "[CV] C=0.001, penalty=l1, solver=lbfgs ...............................\n",
            "[CV] ..... C=0.001, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.001, penalty=l1, solver=lbfgs ...............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ..... C=0.001, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.001, penalty=l1, solver=lbfgs ...............................\n",
            "[CV] ..... C=0.001, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.001, penalty=l1, solver=lbfgs ...............................\n",
            "[CV] ..... C=0.001, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.001, penalty=l1, solver=newton-cg ...........................\n",
            "[CV] . C=0.001, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.001, penalty=l1, solver=newton-cg ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . C=0.001, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.001, penalty=l1, solver=newton-cg ...........................\n",
            "[CV] . C=0.001, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.001, penalty=l1, solver=newton-cg ...........................\n",
            "[CV] . C=0.001, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.559, total=   1.6s\n",
            "[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.560, total=   2.0s\n",
            "[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.560, total=   2.2s\n",
            "[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n",
            "[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.559, total=   1.8s\n",
            "[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.732, total=   2.4s\n",
            "[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.734, total=   2.4s\n",
            "[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.733, total=   2.4s\n",
            "[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n",
            "[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.734, total=   2.4s\n",
            "[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n",
            "[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.732, total=   6.0s\n",
            "[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n",
            "[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.734, total=   6.0s\n",
            "[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n",
            "[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.733, total=   5.9s\n",
            "[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n",
            "[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.734, total=   5.7s\n",
            "[CV] C=0.001, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=0.001, penalty=l2, solver=liblinear, score=0.732, total=   2.1s\n",
            "[CV] C=0.001, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=0.001, penalty=l2, solver=liblinear, score=0.734, total=   2.1s\n",
            "[CV] C=0.001, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=0.001, penalty=l2, solver=liblinear, score=0.733, total=   2.1s\n",
            "[CV] C=0.001, penalty=l2, solver=liblinear ...........................\n",
            "[CV]  C=0.001, penalty=l2, solver=liblinear, score=0.734, total=   2.2s\n",
            "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
            "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
            "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
            "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
            "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
            "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
            "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
            "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.707, total=   2.6s\n",
            "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
            "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.710, total=   2.5s\n",
            "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
            "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.707, total=   2.7s\n",
            "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
            "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.707, total=   2.9s\n",
            "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
            "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.751, total=   4.5s\n",
            "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
            "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.752, total=   7.2s\n",
            "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
            "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.751, total=   4.9s\n",
            "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
            "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.752, total=   4.6s\n",
            "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
            "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.751, total=   8.1s\n",
            "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
            "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.752, total=   8.5s\n",
            "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
            "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.751, total=   8.2s\n",
            "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
            "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.752, total=   8.1s\n",
            "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
            "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.751, total=   3.0s\n",
            "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
            "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.752, total=   2.9s\n",
            "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
            "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.751, total=   2.9s\n",
            "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
            "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.752, total=   2.9s\n",
            "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
            "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
            "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
            "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
            "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
            "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
            "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
            "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.760, total=   3.6s\n",
            "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
            "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.762, total=   3.6s\n",
            "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
            "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.760, total=   3.7s\n",
            "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
            "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.761, total=   3.6s\n",
            "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
            "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.769, total=  15.8s\n",
            "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
            "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.772, total=  15.2s\n",
            "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
            "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.769, total=  15.5s\n",
            "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
            "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.771, total=  16.7s\n",
            "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
            "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.769, total=  11.5s\n",
            "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
            "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.772, total=  11.6s\n",
            "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
            "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.769, total=  11.7s\n",
            "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
            "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.771, total=  12.8s\n",
            "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
            "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.769, total=   6.0s\n",
            "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
            "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.772, total=   5.9s\n",
            "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
            "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.769, total=   5.8s\n",
            "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
            "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.771, total=   4.8s\n",
            "[CV] C=0.5, penalty=l1, solver=lbfgs .................................\n",
            "[CV] ....... C=0.5, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.5, penalty=l1, solver=lbfgs .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... C=0.5, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.5, penalty=l1, solver=lbfgs .................................\n",
            "[CV] ....... C=0.5, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.5, penalty=l1, solver=lbfgs .................................\n",
            "[CV] ....... C=0.5, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=0.5, penalty=l1, solver=newton-cg .............................\n",
            "[CV] ... C=0.5, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.5, penalty=l1, solver=newton-cg .............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ... C=0.5, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.5, penalty=l1, solver=newton-cg .............................\n",
            "[CV] ... C=0.5, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.5, penalty=l1, solver=newton-cg .............................\n",
            "[CV] ... C=0.5, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=0.5, penalty=l1, solver=liblinear .............................\n",
            "[CV] . C=0.5, penalty=l1, solver=liblinear, score=0.773, total=   4.2s\n",
            "[CV] C=0.5, penalty=l1, solver=liblinear .............................\n",
            "[CV] . C=0.5, penalty=l1, solver=liblinear, score=0.775, total=   4.2s\n",
            "[CV] C=0.5, penalty=l1, solver=liblinear .............................\n",
            "[CV] . C=0.5, penalty=l1, solver=liblinear, score=0.774, total=   4.2s\n",
            "[CV] C=0.5, penalty=l1, solver=liblinear .............................\n",
            "[CV] . C=0.5, penalty=l1, solver=liblinear, score=0.775, total=   4.1s\n",
            "[CV] C=0.5, penalty=l2, solver=lbfgs .................................\n",
            "[CV] ..... C=0.5, penalty=l2, solver=lbfgs, score=0.775, total=  26.7s\n",
            "[CV] C=0.5, penalty=l2, solver=lbfgs .................................\n",
            "[CV] ..... C=0.5, penalty=l2, solver=lbfgs, score=0.779, total=  27.5s\n",
            "[CV] C=0.5, penalty=l2, solver=lbfgs .................................\n",
            "[CV] ..... C=0.5, penalty=l2, solver=lbfgs, score=0.776, total=  18.6s\n",
            "[CV] C=0.5, penalty=l2, solver=lbfgs .................................\n",
            "[CV] ..... C=0.5, penalty=l2, solver=lbfgs, score=0.777, total=  29.9s\n",
            "[CV] C=0.5, penalty=l2, solver=newton-cg .............................\n",
            "[CV] . C=0.5, penalty=l2, solver=newton-cg, score=0.775, total=  18.8s\n",
            "[CV] C=0.5, penalty=l2, solver=newton-cg .............................\n",
            "[CV] . C=0.5, penalty=l2, solver=newton-cg, score=0.778, total=  18.7s\n",
            "[CV] C=0.5, penalty=l2, solver=newton-cg .............................\n",
            "[CV] . C=0.5, penalty=l2, solver=newton-cg, score=0.776, total=  19.0s\n",
            "[CV] C=0.5, penalty=l2, solver=newton-cg .............................\n",
            "[CV] . C=0.5, penalty=l2, solver=newton-cg, score=0.777, total=  18.7s\n",
            "[CV] C=0.5, penalty=l2, solver=liblinear .............................\n",
            "[CV] . C=0.5, penalty=l2, solver=liblinear, score=0.775, total=   8.3s\n",
            "[CV] C=0.5, penalty=l2, solver=liblinear .............................\n",
            "[CV] . C=0.5, penalty=l2, solver=liblinear, score=0.778, total=   8.2s\n",
            "[CV] C=0.5, penalty=l2, solver=liblinear .............................\n",
            "[CV] . C=0.5, penalty=l2, solver=liblinear, score=0.776, total=   8.2s\n",
            "[CV] C=0.5, penalty=l2, solver=liblinear .............................\n",
            "[CV] . C=0.5, penalty=l2, solver=liblinear, score=0.777, total=   8.3s\n",
            "[CV] C=1, penalty=l1, solver=lbfgs ...................................\n",
            "[CV] ......... C=1, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1, penalty=l1, solver=lbfgs ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......... C=1, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1, penalty=l1, solver=lbfgs ...................................\n",
            "[CV] ......... C=1, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1, penalty=l1, solver=lbfgs ...................................\n",
            "[CV] ......... C=1, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=1, penalty=l1, solver=newton-cg ...............................\n",
            "[CV] ..... C=1, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1, penalty=l1, solver=newton-cg ...............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ..... C=1, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1, penalty=l1, solver=newton-cg ...............................\n",
            "[CV] ..... C=1, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1, penalty=l1, solver=newton-cg ...............................\n",
            "[CV] ..... C=1, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
            "[CV] ... C=1, penalty=l1, solver=liblinear, score=0.775, total=   4.6s\n",
            "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
            "[CV] ... C=1, penalty=l1, solver=liblinear, score=0.778, total=   4.7s\n",
            "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
            "[CV] ... C=1, penalty=l1, solver=liblinear, score=0.775, total=   4.7s\n",
            "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
            "[CV] ... C=1, penalty=l1, solver=liblinear, score=0.777, total=   4.7s\n",
            "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
            "[CV] ....... C=1, penalty=l2, solver=lbfgs, score=0.776, total= 1.0min\n",
            "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
            "[CV] ....... C=1, penalty=l2, solver=lbfgs, score=0.779, total=  41.2s\n",
            "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
            "[CV] ....... C=1, penalty=l2, solver=lbfgs, score=0.776, total=  31.8s\n",
            "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
            "[CV] ....... C=1, penalty=l2, solver=lbfgs, score=0.778, total=  54.7s\n",
            "[CV] C=1, penalty=l2, solver=newton-cg ...............................\n",
            "[CV] ... C=1, penalty=l2, solver=newton-cg, score=0.776, total=  22.1s\n",
            "[CV] C=1, penalty=l2, solver=newton-cg ...............................\n",
            "[CV] ... C=1, penalty=l2, solver=newton-cg, score=0.779, total=  21.3s\n",
            "[CV] C=1, penalty=l2, solver=newton-cg ...............................\n",
            "[CV] ... C=1, penalty=l2, solver=newton-cg, score=0.776, total=  19.7s\n",
            "[CV] C=1, penalty=l2, solver=newton-cg ...............................\n",
            "[CV] ... C=1, penalty=l2, solver=newton-cg, score=0.778, total=  22.4s\n",
            "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
            "[CV] ... C=1, penalty=l2, solver=liblinear, score=0.776, total=  11.7s\n",
            "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
            "[CV] ... C=1, penalty=l2, solver=liblinear, score=0.779, total=  11.8s\n",
            "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
            "[CV] ... C=1, penalty=l2, solver=liblinear, score=0.776, total=  11.8s\n",
            "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
            "[CV] ... C=1, penalty=l2, solver=liblinear, score=0.778, total=  11.7s\n",
            "[CV] C=2, penalty=l1, solver=lbfgs ...................................\n",
            "[CV] ......... C=2, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=2, penalty=l1, solver=lbfgs ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......... C=2, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=2, penalty=l1, solver=lbfgs ...................................\n",
            "[CV] ......... C=2, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=2, penalty=l1, solver=lbfgs ...................................\n",
            "[CV] ......... C=2, penalty=l1, solver=lbfgs, score=nan, total=   0.1s\n",
            "[CV] C=2, penalty=l1, solver=newton-cg ...............................\n",
            "[CV] ..... C=2, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=2, penalty=l1, solver=newton-cg ...............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ..... C=2, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=2, penalty=l1, solver=newton-cg ...............................\n",
            "[CV] ..... C=2, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=2, penalty=l1, solver=newton-cg ...............................\n",
            "[CV] ..... C=2, penalty=l1, solver=newton-cg, score=nan, total=   0.1s\n",
            "[CV] C=2, penalty=l1, solver=liblinear ...............................\n",
            "[CV] ... C=2, penalty=l1, solver=liblinear, score=0.774, total=   6.0s\n",
            "[CV] C=2, penalty=l1, solver=liblinear ...............................\n",
            "[CV] ... C=2, penalty=l1, solver=liblinear, score=0.777, total=   5.5s\n",
            "[CV] C=2, penalty=l1, solver=liblinear ...............................\n",
            "[CV] ... C=2, penalty=l1, solver=liblinear, score=0.774, total=   5.6s\n",
            "[CV] C=2, penalty=l1, solver=liblinear ...............................\n",
            "[CV] ... C=2, penalty=l1, solver=liblinear, score=0.776, total=   5.6s\n",
            "[CV] C=2, penalty=l2, solver=lbfgs ...................................\n",
            "[CV] ....... C=2, penalty=l2, solver=lbfgs, score=0.775, total= 1.0min\n",
            "[CV] C=2, penalty=l2, solver=lbfgs ...................................\n",
            "[CV] ....... C=2, penalty=l2, solver=lbfgs, score=0.778, total= 1.1min\n",
            "[CV] C=2, penalty=l2, solver=lbfgs ...................................\n",
            "[CV] ....... C=2, penalty=l2, solver=lbfgs, score=0.775, total= 1.2min\n",
            "[CV] C=2, penalty=l2, solver=lbfgs ...................................\n",
            "[CV] ....... C=2, penalty=l2, solver=lbfgs, score=0.777, total= 1.4min\n",
            "[CV] C=2, penalty=l2, solver=newton-cg ...............................\n",
            "[CV] ... C=2, penalty=l2, solver=newton-cg, score=0.775, total=  25.8s\n",
            "[CV] C=2, penalty=l2, solver=newton-cg ...............................\n",
            "[CV] ... C=2, penalty=l2, solver=newton-cg, score=0.778, total=  27.3s\n",
            "[CV] C=2, penalty=l2, solver=newton-cg ...............................\n",
            "[CV] ... C=2, penalty=l2, solver=newton-cg, score=0.775, total=  26.9s\n",
            "[CV] C=2, penalty=l2, solver=newton-cg ...............................\n",
            "[CV] ... C=2, penalty=l2, solver=newton-cg, score=0.777, total=  27.4s\n",
            "[CV] C=2, penalty=l2, solver=liblinear ...............................\n",
            "[CV] ... C=2, penalty=l2, solver=liblinear, score=0.775, total=  14.6s\n",
            "[CV] C=2, penalty=l2, solver=liblinear ...............................\n",
            "[CV] ... C=2, penalty=l2, solver=liblinear, score=0.778, total=  16.1s\n",
            "[CV] C=2, penalty=l2, solver=liblinear ...............................\n",
            "[CV] ... C=2, penalty=l2, solver=liblinear, score=0.775, total=  15.5s\n",
            "[CV] C=2, penalty=l2, solver=liblinear ...............................\n",
            "[CV] ... C=2, penalty=l2, solver=liblinear, score=0.777, total=  14.6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed: 24.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=750001, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 0.5, 1,\n",
              "                               2],\n",
              "                         'penalty': ['l1', 'l2'],\n",
              "                         'solver': ['lbfgs', 'newton-cg', 'liblinear']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WD-0AOxyaU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accuracy score for the model\n",
        "\n",
        "#Accuracy score (True Positives and True negatives)\n",
        "print(grid.score(testX_vector, testY)) \n",
        "\n",
        "#f-1 score (False Negatives and False Positives)\n",
        "print(f1_score(testY, grid.predict(testX_vector), average = None))\n",
        "\n",
        "#Predict method\n",
        "print(grid.predict(testX_vector[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmaL36ie95fo",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "198a9d4b-3e00-46c1-8eab-f29e23da492e"
      },
      "source": [
        "#Testing out our model \n",
        "\n",
        "#Uploading judgement data into a new dataframe\n",
        "uploaded = files.upload()\n",
        "df2 = pd.read_csv(io.BytesIO(uploaded['contestant_judgment.csv']))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6cd9cbe2-c61f-40cb-a784-3ad260ee0838\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6cd9cbe2-c61f-40cb-a784-3ad260ee0838\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving contestant_judgment.csv to contestant_judgment (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2G6-SaOkU1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to vectorize and predict\n",
        "def final(list1):\n",
        "  new_test = tfv.transform(list1)\n",
        "  if grid.predict(new_test) == \"Positive\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "#Loop that appends all the sentiments \n",
        "sentimentList = []\n",
        "for index, rows in df2.iterrows():\n",
        "  list1 = [df2.iloc[index, 2]]\n",
        "  sentimentList.append(final(list1))\n",
        "\n",
        "\n",
        "#Create new column in the contestant judgement data frame and add the values as sentimentList\n",
        "df2['Sentiment_Prediction'] = pd.Series(sentimentList)\n",
        "\n",
        "#Convert the contestant judgement data frame into a new csv file.\n",
        "df2.to_csv('contestant_judgement.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}