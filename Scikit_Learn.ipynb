{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit-Learn",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharvajpatel/AI-Hackathon-Ignition/blob/master/Scikit_Learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crv3IE8tyZxF",
        "colab_type": "text"
      },
      "source": [
        "Machine Learning vs Regular Software:\n",
        "\n",
        "Machine Learning takes input and output and finds equation (data is output, that is why it is so important in ML)\n",
        "Regular software takes input and equation and finds output\n",
        "\n",
        "Example:\n",
        "- Machine Learning can derive the equation of celsius to fahrenheit or vice versa and then can eventually accurately predict the answer by testing the model and putting a lot of data\n",
        "- Regular software will take the equation and either celsius or fahrenheit and tell you the other one.\n",
        "\n",
        "Deep Learning vs Machine Learning:\n",
        "Machine learning uses algorithms to parse data, learn from that data, and make informed decisions based on what it has learned. Deep learning structures algorithms in layers to create an \"artificial neural network‚Äù that can learn and make intelligent decisions on its own.\n",
        "\n",
        "Machine Learning Steps:\n",
        "\n",
        "1) What question are we trying to answer\n",
        "\n",
        "2) Find data to help answer that question\n",
        "\n",
        "3) Process data\n",
        "\n",
        "4) Build Model\n",
        "\n",
        "5) Test/Evauluate model\n",
        "\n",
        "6) Improve model further\n",
        "\n",
        "Note:\n",
        "For the competition they are actually going to supply us with the data so we don't have to worry about finding it (i'm pretty sure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghdi6p20gNdN",
        "colab_type": "text"
      },
      "source": [
        "###Natural Language Processing model (predict whether a review is positive or negative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtfSYltJgFu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import statements for the libraries and initalizing the file into df\n",
        "#Don't know how to work with json, so converted the data into csv. Data is in comment section of Keith's video\n",
        "import json\n",
        "import pandas as pd\n",
        "import io\n",
        "import random\n",
        "from google.colab import files\n",
        "#Scikit imports\n",
        "#Don't import entire library because its too large and will take too long to load\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tqqdw11sizJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All the important classes to manipulate data\n",
        "\n",
        "\n",
        "#Enum class so you can access each value in reviews\n",
        "class Sentiment:\n",
        "  NEG = \"Negative\"\n",
        "  NEU = \"Neutral\"\n",
        "  POS = \"Positive\"\n",
        "\n",
        "#Review class to get the sentiment\n",
        "class Review:\n",
        "  text = \" \"\n",
        "  score = 0\n",
        "\n",
        "  def __init__(self, text, score):\n",
        "    self.score = score\n",
        "    self.text = text\n",
        "    self.sentiment = self.getSentiment() \n",
        "\n",
        "  def getSentiment(self):\n",
        "    if self.score == 1 or self.score == 2:\n",
        "      return Sentiment.NEG\n",
        "    elif self.score == 3:\n",
        "     return Sentiment.NEU\n",
        "    else:\n",
        "      return Sentiment.POS\n",
        "\n",
        "#Review class to even out all the data\n",
        "class ReviewContainer:\n",
        "  def __init__(self, reviews):\n",
        "    self.reviews = reviews\n",
        "  \n",
        "  def getText(self):\n",
        "    return [x.text for x in self.reviews]\n",
        "  \n",
        "  def getSentiment1(self):\n",
        "    return [x.sentiment for x in self.reviews]\n",
        "\n",
        "  def evenly_distribute(self):\n",
        "    negative = list(filter(lambda x: x.sentiment == Sentiment.NEG, self.reviews))\n",
        "    positive = list(filter(lambda x: x.sentiment == Sentiment.POS, self.reviews))\n",
        "    positive_shrunk = positive[:len(negative)]\n",
        "    self.reviews = negative + positive_shrunk\n",
        "    random.shuffle(self.reviews)\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQGHZobFxKur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading Data into from file to dataframe\n",
        "\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(io.BytesIO(uploaded['Books_small_10000.csv'])) #Puts all the data in one variable\n",
        "\n",
        "#Parsing the data for all the important stuff. 2D list with the review, rating, and sentiment\n",
        "reviews = []\n",
        "for index, rows in df.iterrows():\n",
        "  reviews.append(Review(df.iloc[index, 5],df.iloc[index,6]))\n",
        "\n",
        "#Just to make sure that the file loaded in properly\n",
        "print(reviews[0].text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uyPU6oLwLNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entire function is basically the actual algorithm that does the model\n",
        "\n",
        "#Add this at the end\n",
        "def main():\n",
        "  \n",
        "  #Model needs training and testing data so we pass in both\n",
        "\n",
        "  train, test = train_test_split(reviews, test_size = 0.33, random_state = 42)\n",
        "\n",
        "  trainC = ReviewContainer(train)\n",
        "  trainC.evenly_distribute()\n",
        "  testC = ReviewContainer(test)\n",
        "  testC.evenly_distribute()\n",
        "\n",
        "  #X is what we pass in, Y is what our results are. Pass a review get a sentiment\n",
        "  trainX = trainC.getText()\n",
        "  trainY = trainC.getSentiment1()\n",
        "\n",
        "  #Same thing for testing data\n",
        "  testX = testC.getText()\n",
        "  testY = testC.getSentiment1()\n",
        "\n",
        "\n",
        "  #Using vectorizer to sort binary digits\n",
        "\n",
        "  #vectorizer = CountVectorizer()\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  trainX_vector = vectorizer.fit_transform(trainX)\n",
        "  testX_vector = vectorizer.transform(testX)\n",
        "\n",
        "\n",
        "  #Classifying the data\n",
        "\n",
        "  #SVM = support vector machine\n",
        "  clf_svm = svm.SVC(kernel='linear')\n",
        "  clf_svm.fit(trainX_vector, trainY)\n",
        "\n",
        "main()\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faH1cNCMwUua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Analyzing the percent of data that is correct and f1\n",
        "print(clf_svm.predict(testX_vector[0]))\n",
        "\n",
        "print(clf_svm.score(testX_vector, testY))\n",
        "\n",
        "#f-1 score\n",
        "\n",
        "print(f1_score(testY, clf_svm.predict(testX_vector), average = None))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDkGhvsrVV0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Final product\n",
        "\n",
        "def final(list1):\n",
        "  new_test = vectorizer.transform(list1)\n",
        "  return clf_svm.predict(new_test)\n",
        "\n",
        "user_val = input(\"Enter some feedback(press enter to exit): \")\n",
        "list1 = []\n",
        "list1.append(user_val)\n",
        "print(final(list1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}